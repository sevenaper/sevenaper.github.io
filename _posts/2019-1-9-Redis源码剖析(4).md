---
title: Redis源码剖析:字典
key: 20190107
tags: Redis
---

## 字典

### 字典的实现

Redis的字典使用哈希表作为底层实现，一个哈希表里面有多个哈希表节点，而每个哈希表节点就保存了字典中的一个键值对。

#### 哈希表

```c
typedef struct dictht {
    dictEntry **table;//哈希表数组
    unsigned long size;//哈希表大小
    unsigned long sizemask;//哈希表掩码，用于计算索引值，总是等于size-1
    unsigned long used;//该哈希表已有节点的数量
} dictht;
```

![](https://s2.ax1x.com/2019/02/12/kdcEZt.png)

#### 哈希表节点

哈希表节点使用dictEntry表示，每个dictEntry结构都保存这一个键值对

```c
typedef struct dictEntry {
    void *key;
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
        double d;
    } v;
    struct dictEntry *next;//指向下一个哈希表节点，形成链表
} dictEntry;
```

key属性保存着键值对中的键，v属性保存着键值对中的值，可以为一个void指针，或者uint64_t整数，又或者是一个int64_t整数。

next属性形成另一个哈希表节点，来解决键冲突问题。

[![](https://s2.ax1x.com/2019/02/12/kdcNJU.md.png)](https://imgchr.com/i/kdcNJU)

#### 字典

```c
typedef struct dictType {
    //计算哈希值
    uint64_t (*hashFunction)(const void *key);
    //复制键
    void *(*keyDup)(void *privdata, const void *key);
    //复制值
    void *(*valDup)(void *privdata, const void *obj);
    //比较键
    int (*keyCompare)(void *privdata, const void *key1, const void *key2);
    //销毁键
    void (*keyDestructor)(void *privdata, void *key);
    //销毁值
    void (*valDestructor)(void *privdata, void *obj);
} dictType;

typedef struct dict {
    dictType *type;
    void *privdata;
    dictht ht[2];
    long rehashidx; /* rehashing not in progress if rehashidx == -1 */
    unsigned long iterators; /* number of iterators currently running */
} dict;
```

type属性和privdata属性是针对不同类型的键值对，为创建多态字典设置。其中type保存了一些特定操作的函数，而privdata保存了需要传给那些的类型特定函数的可选参数。

ht每一个项都是一个dictht哈希表，一般情况下只使用ht[0]，ht[1]哈希表只会在对ht[0]哈希表进行rehash时使用。

> 在`dict`的内部，维护了两张哈希表，作用等同于是一对滚动数组，一张表是旧表，一张表是新表，当`hashtable`的大小需要动态改变的时候，旧表中的元素就往新开辟的新表中迁移，当下一次变动大小，当前的新表又变成了旧表，以此达到资源的复用和效率的提升。

### 哈希算法

```c
hash = dict->type->hashFunction(k0);
index = hash & dict->ht[x].sizemask;
```

然后根据算出的索引值放到哈希表的相应位置中。当字典被用作数据库的底层实现，或者　哈希键的底层实现时，Redis使用MurmurHash2算法来计算哈希值。

### 解决键冲突

使用拉链法

### rehash

随着操作的不断进行，哈希表保存的键值对会逐渐增多或者减少，为了让好戏标的负载因子维持在一个合理的范围内，当哈希表保存的键值对数量太多或者太少时，程序需要对哈希表的大小进行相应的扩展或者收缩。当ht[0]包含的键值对都迁移到ht[1]，后，将ht[1]设置为ht[0]，并在ht[1]创建一个空白哈希表，为下一次rehash做准备

### 渐进式哈希

```c
int dictRehash(dict *d, int n) {
    int empty_visits = n*10; /* Max number of empty buckets to visit. */
    if (!dictIsRehashing(d)) return 0;

    while(n-- && d->ht[0].used != 0) {
        dictEntry *de, *nextde;

        /* Note that rehashidx can't overflow as we are sure there are more
         * elements because ht[0].used != 0 */
        assert(d->ht[0].size > (unsigned long)d->rehashidx);
        while(d->ht[0].table[d->rehashidx] == NULL) {
            d->rehashidx++;
            if (--empty_visits == 0) return 1;
        }
        de = d->ht[0].table[d->rehashidx];
        /* Move all the keys in this bucket from the old to the new hash HT */
        while(de) {
            uint64_t h;

            nextde = de->next;
            /* Get the index in the new hash table */
            h = dictHashKey(d, de->key) & d->ht[1].sizemask;
            de->next = d->ht[1].table[h];
            d->ht[1].table[h] = de;
            d->ht[0].used--;
            d->ht[1].used++;
            de = nextde;
        }
        d->ht[0].table[d->rehashidx] = NULL;
        d->rehashidx++;
    }

    /* Check if we already rehashed the whole table... */
    if (d->ht[0].used == 0) {
        zfree(d->ht[0].table);
        d->ht[0] = d->ht[1];
        _dictReset(&d->ht[1]);
        d->rehashidx = -1;
        return 0;
    }

    /* More to rehash... */
    return 1;
}

```

rehash是以bucket(桶)为基本单位进行渐进式的数据迁移的，每步完成一个bucket的迁移，直至所有数据迁移完毕。一个bucket对应哈希表数组中的一条entry链表。新版本的dictRehash()还加入了一个最大访问空桶数(empty_visits)的限制来进一步减小可能引起阻塞的时间。

接下来我们深扒一下这个函数的具体实现。

1. 判断dict是否正在rehashing，只有是，才能继续往下进行，否则已经结束哈希过程，直接返回。
2. 接着是分n步进行的渐进式哈希主体部分（n由函数参数传入），在while的条件里面加入对.used旧表中剩余元素数目的观察，增加安全性。
3. 一个runtime的断言保证一下渐进式哈希的索引没有越界。
4. 接下来一个小while是为了跳过空桶，同时更新剩余可以访问的空桶数，empty_visits这个变量的作用之前已经说过了。
5. 现在我们来到了当前的bucket，在下一个while(de)中把其中的所有元素都迁移到ht[1]中，索引值是辅助了哈希表的大小掩码计算出来的，可以保证不会越界。同时更新了两张表的当前元素数目。
6. 每一步rehash结束，都要增加索引值，并且把旧表中已经迁移完毕的bucket置为空指针。
7. 最后判断一下旧表是否全部迁移完毕，若是，则回收空间，重置旧表，重置渐进式哈希的索引，否则用返回值告诉调用方，dict内仍然有数据未迁移。 


渐进式哈希的精髓在于：数据的迁移不是一次性完成的，而是可以通过dictRehash()这个函数分步规划的，并且调用方可以及时知道是否需要继续进行渐进式哈希操作。如果dict数据结构中存储了海量的数据，那么一次性迁移势必带来redis性能的下降，别忘了redis是单线程模型，在实时性要求高的场景下这可能是致命的。而渐进式哈希则将这种代价可控地分摊了，调用方可以在dict做插入，删除，更新的时候执行dictRehash()，最小化数据迁移的代价。 

在迁移的过程中，数据是在新表还是旧表中并不是一个非常急迫的需求，迁移的过程并不会丢失数据，在旧表中找不到再到新表中寻找就是了。

